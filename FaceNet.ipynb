{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgjh0hM3gEcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d89ceaed-955e-4fb6-9170-c1a9dcaea074"
      },
      "source": [
        "import tensorflow as tf#\n",
        "import numpy as np#\n",
        "import os\n",
        "from numpy import genfromtxt\n",
        "from keras import backend as K\n",
        "#from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.layers import concatenate\n",
        "\n",
        "from keras.models import Model\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "#from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Flatten, Dense, Concatenate, Dot, Lambda, Input,Conv2D, MaxPool2D, BatchNormalization, Add, ZeroPadding2D, Activation, AveragePooling2D\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpE-l-BFsBiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np#\n",
        "import os\n",
        "from numpy import genfromtxt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten, Dense, Concatenate, Dot, Lambda, Input, Conv2D, MaxPool2D, BatchNormalization, Add, ZeroPadding2D, Activation, AveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAq90_0ShpOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def conv2d_bn(x,\n",
        "              layer=None,\n",
        "              cv1_out=None,\n",
        "              cv1_filter=(1, 1),\n",
        "              cv1_strides=(1, 1),\n",
        "              cv2_out=None,\n",
        "              cv2_filter=(3, 3),\n",
        "              cv2_strides=(1, 1),\n",
        "              padding=None):\n",
        "    num = '' if cv2_out == None else '1'\n",
        "    tensor = Conv2D(cv1_out, cv1_filter, strides=cv1_strides, data_format='channels_first', name=layer+'_conv'+num)(x)\n",
        "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+num)(tensor)\n",
        "    tensor = Activation('relu')(tensor)\n",
        "    if padding == None:\n",
        "        return tensor\n",
        "    tensor = ZeroPadding2D(padding=padding, data_format='channels_first')(tensor)\n",
        "    if cv2_out == None:\n",
        "        return tensor\n",
        "    tensor = Conv2D(cv2_out, cv2_filter, strides=cv2_strides, data_format='channels_first', name=layer+'_conv'+'2')(tensor)\n",
        "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+'2')(tensor)\n",
        "    tensor = Activation('relu')(tensor)\n",
        "    return tensor\n",
        "\n",
        "def inception_block_1a(X):\n",
        "    \"\"\"\n",
        "    Implementation of an inception block\n",
        "    \"\"\"\n",
        "    \n",
        "    X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name ='inception_3a_3x3_conv1')(X)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name = 'inception_3a_3x3_bn1')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "    X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3a_3x3_conv2')(X_3x3)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_3x3_bn2')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    \n",
        "    \n",
        "    X_5x5 = Conv2D(16, (1, 1), data_format='channels_first', name='inception_3a_5x5_conv1')(X)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn1')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "    X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "    X_5x5 = Conv2D(32, (5, 5), data_format='channels_first', name='inception_3a_5x5_conv2')(X_5x5)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn2')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "    X_pool = MaxPool2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3a_pool_conv')(X_pool)\n",
        "    X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_pool_bn')(X_pool)\n",
        "    X_pool = Activation('relu')(X_pool)\n",
        "    X_pool = ZeroPadding2D(padding=((3, 4), (3, 4)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3a_1x1_conv')(X)\n",
        "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_1x1_bn')(X_1x1)\n",
        "    X_1x1 = Activation('relu')(X_1x1)\n",
        "        \n",
        "    # CONCAT\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_1b(X):\n",
        "    X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name='inception_3b_3x3_conv1')(X)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn1')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "    X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3b_3x3_conv2')(X_3x3)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn2')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "\n",
        "    X_5x5 = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3b_5x5_conv1')(X)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn1')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "    X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "    X_5x5 = Conv2D(64, (5, 5), data_format='channels_first', name='inception_3b_5x5_conv2')(X_5x5)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn2')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_pool_conv')(X_pool)\n",
        "    X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_pool_bn')(X_pool)\n",
        "    X_pool = Activation('relu')(X_pool)\n",
        "    X_pool = ZeroPadding2D(padding=(4, 4), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_1x1_conv')(X)\n",
        "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_1x1_bn')(X_1x1)\n",
        "    X_1x1 = Activation('relu')(X_1x1)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_1c(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_3c_3x3',\n",
        "                           cv1_out=128,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=256,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(1, 1))\n",
        "\n",
        "    X_5x5 = conv2d_bn(X,\n",
        "                           layer='inception_3c_5x5',\n",
        "                           cv1_out=32,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=64,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(2, 2))\n",
        "\n",
        "    X_pool = MaxPool2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_2a(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_4a_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=192,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_5x5 = conv2d_bn(X,\n",
        "                           layer='inception_4a_5x5',\n",
        "                           cv1_out=32,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=64,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(2, 2))\n",
        "\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = conv2d_bn(X_pool,\n",
        "                           layer='inception_4a_pool',\n",
        "                           cv1_out=128,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           padding=(2, 2))\n",
        "    X_1x1 = conv2d_bn(X,\n",
        "                           layer='inception_4a_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_2b(X):\n",
        "    #inception4e\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_4e_3x3',\n",
        "                           cv1_out=160,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=256,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(1, 1))\n",
        "    X_5x5 = conv2d_bn(X,\n",
        "                           layer='inception_4e_5x5',\n",
        "                           cv1_out=64,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=128,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(2, 2))\n",
        "    \n",
        "    X_pool = MaxPool2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_3a(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_5a_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=384,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = conv2d_bn(X_pool,\n",
        "                           layer='inception_5a_pool',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_1x1 = conv2d_bn(X,\n",
        "                           layer='inception_5a_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "\n",
        "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_3b(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_5b_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=384,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_pool = MaxPool2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = conv2d_bn(X_pool,\n",
        "                           layer='inception_5b_pool',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1))\n",
        "    X_pool = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = conv2d_bn(X,\n",
        "                           layer='inception_5b_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "\n",
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss as defined by formula (3)\n",
        "    \n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128)\n",
        "    \n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    \n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "    \n",
        "    ### START CODE HERE ### (≈ 4 lines)\n",
        "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
        "    pos_dist = tf.reduce_sum( tf.square( tf.subtract( anchor,positive ) ), axis=-1 )\n",
        "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
        "    neg_dist = tf.reduce_sum( tf.square( tf.subtract( anchor,negative ) ), axis=-1 )\n",
        "    # Step 3: subtract the two previous distances and add alpha.\n",
        "    basic_loss =  tf.maximum( tf.subtract(pos_dist,neg_dist) + alpha, 0)\n",
        "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
        "    loss = tf.reduce_sum(basic_loss)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return loss\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_TMfb2AmYTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_input = Input((3, 96, 96))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhTzdE_9g0fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input((3, 96, 96))\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # First Block\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 1, name = 'bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1))(X)\n",
        "    X = MaxPool2D((3, 3), strides = 2)(X)\n",
        "    \n",
        "    # Second Block\n",
        "    X = Conv2D(64, (1, 1), strides = (1, 1), name = 'conv2')(X)\n",
        "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1))(X)\n",
        "\n",
        "    # Second Block\n",
        "    X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv3')(X)\n",
        "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1))(X)\n",
        "    X = MaxPool2D(pool_size = 3, strides = 2)(X)\n",
        "    \n",
        "    # Inception 1: a/b/c\n",
        "    X = inception_block_1a(X)\n",
        "    X = inception_block_1b(X)\n",
        "    X = inception_block_1c(X)\n",
        "    \n",
        "    # Inception 2: a/b\n",
        "    X = inception_block_2a(X)\n",
        "    X = inception_block_2b(X)\n",
        "    \n",
        "    # Inception 3: a/b\n",
        "    X = inception_block_3a(X)\n",
        "    X = inception_block_3b(X)\n",
        "    \n",
        "    # Top layer\n",
        "    X = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), data_format='channels_first')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(128, name='dense_layer')(X)\n",
        "    \n",
        "    # L2 normalization\n",
        "    X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
        "\n",
        "    # Create model instance\n",
        "    model = Model(inputs = X_input, outputs = X, name='FaceRecoModel')\n",
        "\n",
        "    input1 = Input((3,96,96))\n",
        "    input2 = Input((3,96,96))\n",
        "    input3 = Input((3,96,96))\n",
        "\n",
        "    anchor = model(input1)  #se le asigna 3 entradas al modelo\n",
        "    positive = model(input2)\n",
        "    negative = model(input3)\n",
        "\n",
        "    merge_layer = Concatenate()([anchor, positive, negative]) #se concatena\n",
        "\n",
        "    model_final = Model(inputs=[input1, input2, input3], outputs=merge_layer)\n",
        "\n",
        "    model_final.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggv4VDuEKjdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d0af5fe5-b4b0-4184-8283-44c84db3688f"
      },
      "source": [
        "model_final.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 3, 96, 96)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 3, 96, 96)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 3, 96, 96)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "FaceRecoModel (Model)           (None, 128)          3743280     input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 384)          0           FaceRecoModel[1][0]              \n",
            "                                                                 FaceRecoModel[2][0]              \n",
            "                                                                 FaceRecoModel[3][0]              \n",
            "==================================================================================================\n",
            "Total params: 3,743,280\n",
            "Trainable params: 3,733,968\n",
            "Non-trainable params: 9,312\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IjFDhwHLSAg",
        "colab_type": "text"
      },
      "source": [
        "#Cargamos los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GDx_MlVLY-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/MemoriaProyectoGrado/faceNetWeights.h5\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcVy9L8-lXOE",
        "colab_type": "text"
      },
      "source": [
        "##Prediccion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4XfqHjAnTtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import io\n",
        "from skimage import color\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qskY7znDN1DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_to_encoding(image_path, model):\n",
        "    img1 = io.imread(image_path)\n",
        "    #img = img1[...,::-1]\n",
        "    img = np.around(np.transpose(img1, (2,0,1))/255.0, decimals=12)\n",
        "    x_train = np.array([img])\n",
        "    embedding = model.predict(x_train)\n",
        "    #embedding = model.predict_on_batch(x_train)\n",
        "    return embedding"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us1HqToB77_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anchor = io.imread(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id1/96/id1_1_1.jpg\")\n",
        "positive = io.imread(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id1/96/id1_4_1.jpg\")\n",
        "negative = io.imread(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id4/96/2.jpg\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIFpWtx79LyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anchor = np.around(np.transpose(anchor, (2,0,1))/255.0, decimals=12)\n",
        "positive = np.around(np.transpose(positive, (2,0,1))/255.0, decimals=12)\n",
        "negative = np.around(np.transpose(negative, (2,0,1))/255.0, decimals=12)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2DcEYOu_Klq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "e891911b-f500-4e6c-8c2b-bf0c864c01c7"
      },
      "source": [
        "anchor\n",
        "train_images.reshape([772,64,64,1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d543b3fc7454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m772\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cnAVoKo60qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = model_final.predict([anchor.reshape([1,3,96,96]),positive.reshape([1,3,96,96]) , negative.reshape([1,3,96,96])])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS5T8nn1A9nl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c1f744f-1202-4068-8be7-2e0b05233cac"
      },
      "source": [
        "p.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 384)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO2hd24OlqfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "database = {}\n",
        "database[\"id1\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id1/96/id1_1_1.jpg\", model)\n",
        "database[\"id2\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id2/96/1.jpg\", model)\n",
        "database[\"id3\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id3/96/1.jpg\", model)\n",
        "database[\"id4\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id4/96/1.jpg\", model)\n",
        "database[\"id5\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id5/96/1.jpg\", model)\n",
        "database[\"id6\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id6/96/1.jpg\", model)\n",
        "database[\"id7\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id7/96/1.jpg\", model)\n",
        "database[\"id8\"] = img_to_encoding(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id8/96/1.jpg\", model)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH4cG091n2dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def who_is_it(image_path, database, model):\n",
        "    \"\"\"\n",
        "    Implements face recognition for the office by finding who is the person on the image_path image.\n",
        "    \n",
        "    Arguments:\n",
        "    image_path -- path to an image\n",
        "    database -- database containing image encodings along with the name of the person on the image\n",
        "    model -- your Inception model instance in Keras\n",
        "    \n",
        "    Returns:\n",
        "    min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
        "    identity -- string, the name prediction for the person on image_path\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### \n",
        "    \n",
        "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    \n",
        "    ## Step 2: Find the closest encoding ##\n",
        "    \n",
        "    # Initialize \"min_dist\" to a large value, say 100 (≈1 line)\n",
        "    min_dist = 100\n",
        "    \n",
        "    # Loop over the database dictionary's names and encodings.\n",
        "    for (name, db_enc) in database.items():\n",
        "        \n",
        "        # Compute L2 distance between the target \"encoding\" and the current db_enc from the database. (≈ 1 line)\n",
        "        dist = np.linalg.norm( encoding - db_enc )\n",
        "\n",
        "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    if min_dist > 0.7:\n",
        "        print(\"Not in the database.\")\n",
        "    else:\n",
        "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        \n",
        "    return min_dist, identity\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irhCzmU3qbov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e231488a-2fff-43a4-e101-dc57f9d1dd3b"
      },
      "source": [
        "who_is_it(\"/content/drive/My Drive/MemoriaProyectoGrado/IMÁGENES/id6/96/10.jpg\", database, model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not in the database.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7296427, 'id6')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JjtNk5-tDtj",
        "colab_type": "text"
      },
      "source": [
        "## Prepaparacion para el reentrenamiento (Contrucción del dataset)"
      ]
    }
  ]
}